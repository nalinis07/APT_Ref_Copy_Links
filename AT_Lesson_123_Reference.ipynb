{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalinis07/APT_Ref_Copy_Links/blob/MASTER/AT_Lesson_123_Reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98EVEazf_LLM"
      },
      "source": [
        "# Lesson 123: kNN Regression I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et9XG36iRrqj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMa2XShG_Uv8"
      },
      "source": [
        "**WARNING:** The reference notebook is meant **ONLY** for a teacher. Please **DO NOT** share it with any student.\n",
        "\n",
        "The contents of the reference notebook are meant only to prepare a teacher for a class. To conduct the class, use the class copy of the reference notebook. The link and the instructions for the same are provided in the **Notes To The Teacher** section.\n",
        "\n",
        "\n",
        "|Particulars|Description|\n",
        "|-|-|\n",
        "|**Topic**|kNN Regression I |\n",
        "|||\n",
        "|**Class Description**|In this class, a student will learn how to use kNN algorithm to solve a regression problem statement|\n",
        "|||\n",
        "|**Class**|C123|\n",
        "|||\n",
        "|**Class Time**|55 minutes|\n",
        "|||\n",
        "|**Goal**|Build a Random Forest classifier model|\n",
        "||Build an SVC model.|\n",
        "||Build a Decision Tree classifier model|\n",
        "||Understand the concept of kNN regression|\n",
        "|||\n",
        "|**Teacher Resources**|Google Account|\n",
        "||Laptop with internet connectivity|\n",
        "||Earphones with mic|\n",
        "|||\n",
        "|**Student Resources**|Google Account|\n",
        "||Laptop with internet connectivity|\n",
        "||Earphones with mic|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSxtp-QD_a-F"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVZAZgUVRnhr"
      },
      "source": [
        "### Warm-up Quiz\n",
        "\n",
        "```\n",
        "TEACHER\n",
        "I have an exciting quiz question for you! Are you ready to answer this question?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "Yes.\n",
        "```\n",
        "\n",
        "**Instructions for the Teacher:**\n",
        "- Please click on the \"Quiz Time\" button on the bottom right corner of your screen to start the In-Class Quiz. <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/quiz-time.png' width = 150>\n",
        "\n",
        "- A quiz will be visible to both you and the student. Encourage the student to answer the quiz question.\n",
        "\n",
        "- The student may choose the wrong option, help the student to think correctly about the question and then answer again.\n",
        "\n",
        "- After the student selects the correct option, the \"End Quiz\" button will start appearing on your screen. <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/end-quiz.png' width = 150>  \n",
        "\n",
        "- Click the \"End quiz\" button to close the quiz pop-up and continue the class.\n",
        "  \n",
        "- Do not spend more than 2 minutes on this quiz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hloIsu2kRoZr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZUjQYr0_gu0"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous class, we implemented kNN classifier using `sklearn` module of Python. We also learned how to decide the number of neighbours ($k$) for kNN classifier.\n",
        "\n",
        "In today's class, we will implement three more classification algorithms for water quality prediction dataset and compare the performance of these algorithms with kNN classifier.\n",
        "\n",
        "We will also understand the core idea behind kNN regressor and how to use it to solve regression problems in machine learning.\n",
        "\n",
        "\n",
        "Before that, let us revisit the problem statement and recall the concepts learned in the previous class and start this class from **Activity 1: Building Decision Tree Classifier Model**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHVLPGyJ_Zns"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxbhtj--_axi"
      },
      "source": [
        "#### Problem Statement\n",
        "\n",
        "Safe drinking water is essential for every form of life on earth. for public health. The United Nations (UN) and other countries declared access to safe drinking water as a fundamental human right. This is important as a health and development issue at a national, regional, and local level.\n",
        "\n",
        "You are provided with a dataset consisting of water quality metrics for 3276 different water bodies. Your job is to  create a model to determine if the sample tested from the water body is fit for human consumption or not.\n",
        "\n",
        "Following are the attributes of this dataset:\n",
        "\n",
        "\n",
        "1. `ph`: The pH value indicates the acidic or alkaline condition of water status. The pH of pure water is 7. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5.\n",
        "\n",
        "2. `Hardness`: Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels.\n",
        "\n",
        "3. `Solids`: Also known as TDS (total dissolved solids). Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, etc. These minerals produced un-wanted taste and diluted colour in appearance of water.  The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l prescribed for drinking purposes.\n",
        "\n",
        "4. `Chloramines`: Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per litre ($mg/L$ or 4 parts per million (ppm)) are considered safe in drinking water.\n",
        "\n",
        "5. `Sulfate`: Sulfates are naturally occurring substances that are found in minerals, soil, and rocks.  Sulfate concentration in seawater is about 2,700 milligrams per litre ($mg/L$). It ranges from 3 to 30 $mg/L$ in most freshwater supplies.\n",
        "\n",
        "\n",
        "6. `Conductivity`: Pure water is not a good conductor of electric current rather’s a good insulator.  Electrical conductivity (EC) measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceed 400 micro siemens per centimetre ($\\mu S/cm$).\n",
        "\n",
        "7. `Organic_carbon`: Total Organic Carbon (TOC) is a measure of the total amount of carbon in organic compounds in pure water.\n",
        "\n",
        "8. `Trihalomethanes`: Trihalomethanes (THMs) are chemicals which may be found in water treated with chlorine. THM levels up to 80 ppm is considered safe in drinking water.\n",
        "\n",
        "9. `Turbidity`: The turbidity of water depends on the quantity of solid matter present in the suspended state. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n",
        "\n",
        "10. `Potability`: Indicates if water is safe for human consumption where `1` means Potable and `0` means Not potable.\n",
        "\n",
        "\n",
        "**Dataset Credits:** https://www.kaggle.com/adityakadiwal/water-potability\n",
        "\n",
        "**Dataset Link:** https://s3-whjr-v2-prod-bucket.whjr.online/69e55114-dbd8-46c8-9c0a-4bdf19008d79.csv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "uJQrhAirce86",
        "outputId": "e1591c2b-6887-4c2b-e763-77c0067af0ff"
      },
      "source": [
        "# Import the Python modules and the data.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "water_df = pd.read_csv(\"https://s3-whjr-v2-prod-bucket.whjr.online/69e55114-dbd8-46c8-9c0a-4bdf19008d79.csv\")\n",
        "water_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ph    Hardness        Solids  ...  Trihalomethanes  Turbidity  Potability\n",
              "0       NaN  204.890455  20791.318981  ...        86.990970   2.963135           0\n",
              "1  3.716080  129.422921  18630.057858  ...        56.329076   4.500656           0\n",
              "2  8.099124  224.236259  19909.541732  ...        66.420093   3.055934           0\n",
              "3  8.316766  214.373394  22018.417441  ...       100.341674   4.628771           0\n",
              "4  9.092223  181.101509  17978.986339  ...        31.997993   4.075075           0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAjJnrbklm62"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYdHVXeSlloO"
      },
      "source": [
        "#### Recap\n",
        "#### Data Preprocessing\n",
        "\n",
        "Let's find out the total number of rows and columns, data types of columns and missing values (if exist) in the `water_df` DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eklSHu1mmdNx",
        "outputId": "1760afb9-56d8-45bc-8eb9-39fbbe2e1101"
      },
      "source": [
        "# Get the total number of rows and columns, data types of columns and missing values (if exist) in the dataset.\n",
        "water_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QfboNo_prXd",
        "outputId": "521f4f03-e30a-45f6-c5c4-015ab9cbc38b"
      },
      "source": [
        "# Check missing values using the 'isnull().sum()' function.\n",
        "water_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 491\n",
              "Hardness             0\n",
              "Solids               0\n",
              "Chloramines          0\n",
              "Sulfate            781\n",
              "Conductivity         0\n",
              "Organic_carbon       0\n",
              "Trihalomethanes    162\n",
              "Turbidity            0\n",
              "Potability           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSiX20sqq2nH",
        "outputId": "a99e109d-c793-4d49-cedc-7207a9d7274a"
      },
      "source": [
        "# Check the percentage of missing values\n",
        "water_df.isnull().sum() * 100 / water_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 14.987790\n",
              "Hardness            0.000000\n",
              "Solids              0.000000\n",
              "Chloramines         0.000000\n",
              "Sulfate            23.840049\n",
              "Conductivity        0.000000\n",
              "Organic_carbon      0.000000\n",
              "Trihalomethanes     4.945055\n",
              "Turbidity           0.000000\n",
              "Potability          0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROLO7flLwIXZ"
      },
      "source": [
        "# Handle missing value with median of features\n",
        "water_df[\"ph\"].fillna(value = water_df[\"ph\"].median(), inplace = True)\n",
        "water_df[\"Sulfate\"].fillna(value = water_df[\"Sulfate\"].median(), inplace = True)\n",
        "water_df[\"Trihalomethanes\"].fillna(value = water_df[\"Trihalomethanes\"].median(), inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPQ9rJvrxIax",
        "outputId": "1ff90d5c-74b2-4e77-edfc-104a320ce275"
      },
      "source": [
        "# Check the percentage of missing values\n",
        "water_df.isnull().sum() * 100 / water_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 0.0\n",
              "Hardness           0.0\n",
              "Solids             0.0\n",
              "Chloramines        0.0\n",
              "Sulfate            0.0\n",
              "Conductivity       0.0\n",
              "Organic_carbon     0.0\n",
              "Trihalomethanes    0.0\n",
              "Turbidity          0.0\n",
              "Potability         0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E7XyAF4xe5D"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apfWC4vLxgIj"
      },
      "source": [
        "#### Data Preparation\n",
        "\n",
        "For our dataset, the column `Potability` is the target variable and other columns except `Potability` are the feature variables.\n",
        "Let us create a countplot to display the count of  each target class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "efOp10WONzIZ",
        "outputId": "0f9faf5a-3c03-47b4-fb43-7a5a6e19d419"
      },
      "source": [
        "# Split the data into dependent and independent features\n",
        "features_df = water_df.drop(['Potability'], axis = 1)\n",
        "target_df = water_df['Potability']\n",
        "features_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ph    Hardness  ...  Trihalomethanes  Turbidity\n",
              "0  7.036752  204.890455  ...        86.990970   2.963135\n",
              "1  3.716080  129.422921  ...        56.329076   4.500656\n",
              "2  8.099124  224.236259  ...        66.420093   3.055934\n",
              "3  8.316766  214.373394  ...       100.341674   4.628771\n",
              "4  9.092223  181.101509  ...        31.997993   4.075075\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PqKj1bSLO44j",
        "outputId": "4212416c-7aa3-49b8-c34d-c43564c76816"
      },
      "source": [
        "# Normalise the column values.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "scaled_features = standard_scaler.fit_transform(features_df)\n",
        "X_scaled = pd.DataFrame(scaled_features)\n",
        "X_scaled.columns = features_df.columns\n",
        "X_scaled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.025474</td>\n",
              "      <td>0.259195</td>\n",
              "      <td>-0.139471</td>\n",
              "      <td>0.112415</td>\n",
              "      <td>0.965957</td>\n",
              "      <td>1.708954</td>\n",
              "      <td>-1.180651</td>\n",
              "      <td>1.305434</td>\n",
              "      <td>-1.286298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.284717</td>\n",
              "      <td>-2.036414</td>\n",
              "      <td>-0.385987</td>\n",
              "      <td>-0.307694</td>\n",
              "      <td>-0.014799</td>\n",
              "      <td>2.062575</td>\n",
              "      <td>0.270597</td>\n",
              "      <td>-0.639186</td>\n",
              "      <td>0.684218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.697319</td>\n",
              "      <td>0.847665</td>\n",
              "      <td>-0.240047</td>\n",
              "      <td>1.360594</td>\n",
              "      <td>-0.014799</td>\n",
              "      <td>-0.094032</td>\n",
              "      <td>0.781117</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>-1.167365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.845393</td>\n",
              "      <td>0.547651</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.592008</td>\n",
              "      <td>0.644130</td>\n",
              "      <td>-0.778830</td>\n",
              "      <td>1.255134</td>\n",
              "      <td>2.152154</td>\n",
              "      <td>0.848412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.372982</td>\n",
              "      <td>-0.464429</td>\n",
              "      <td>-0.460249</td>\n",
              "      <td>-0.363698</td>\n",
              "      <td>-0.649522</td>\n",
              "      <td>-0.343939</td>\n",
              "      <td>-0.824357</td>\n",
              "      <td>-2.182297</td>\n",
              "      <td>0.138786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ph  Hardness    Solids  ...  Organic_carbon  Trihalomethanes  Turbidity\n",
              "0 -0.025474  0.259195 -0.139471  ...       -1.180651         1.305434  -1.286298\n",
              "1 -2.284717 -2.036414 -0.385987  ...        0.270597        -0.639186   0.684218\n",
              "2  0.697319  0.847665 -0.240047  ...        0.781117         0.000800  -1.167365\n",
              "3  0.845393  0.547651  0.000493  ...        1.255134         2.152154   0.848412\n",
              "4  1.372982 -0.464429 -0.460249  ...       -0.824357        -2.182297   0.138786\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEfEMPnVmVd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRuBTtSxXalQ"
      },
      "source": [
        "#### Building kNN Classifier Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqdMY0qxYFgV",
        "outputId": "89720ed4-99b8-40a3-fe79-a6eabc8bac99"
      },
      "source": [
        "# Perform train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, target_df, test_size = 0.3,\n",
        "                                                    random_state = 42, stratify = target_df)\n",
        "\n",
        "# Print the shape of train and test sets.\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (2293, 9)\n",
            "Shape of X_test: (983, 9)\n",
            "Shape of y_train: (2293,)\n",
            "Shape of y_test: (983,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeo7GeCVbWnh",
        "outputId": "743a62b6-5d56-4a53-9e24-3df388a5bb3a"
      },
      "source": [
        "# Train kNN classifier model for 'k = 3'\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn3 = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn3.fit(X_train, y_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train set and test set.\n",
        "print(\"Train set accuracy:\", knn3.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", knn3.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.8146532926297427\n",
            "Test set accuracy: 0.612410986775178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG_xWwMnYdGK",
        "outputId": "15bcb6b5-d55f-49cb-f924-88694488d480"
      },
      "source": [
        "# Train kNN classifier model for 'k = 7'\n",
        "knn7 = KNeighborsClassifier(n_neighbors = 7)\n",
        "knn7.fit(X_train, y_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train set and test set.\n",
        "print(\"Train set accuracy:\", knn7.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", knn7.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.7313563017880506\n",
            "Test set accuracy: 0.6185147507629705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFLEwE6-oumY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYHSt9ACHB_n"
      },
      "source": [
        "#### Finding an optimal $k$ value\n",
        "\n",
        "We need to find a value of $k$ which can give a  good train and test set accuracy. For this, we can determine the accuracy scores for neighbours from `1` to `20` and plot these scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "m8JRBGpRS-48",
        "outputId": "05bd629d-771f-47c8-db0b-50a0ce432570"
      },
      "source": [
        "# Plot accuracy scores of train and test sets for 1 to 20 neighbours.\n",
        "accuracy_train = []\n",
        "accuracy_test= []\n",
        "\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    accuracy_train.append(knn.score(X_train, y_train))\n",
        "    accuracy_test.append(knn.score(X_test, y_test))\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.grid()\n",
        "plt.xticks(range(1, 21, 1))\n",
        "plt.plot(range(1, 21), accuracy_train, color= 'blue', label = \"Train set accuracy\")\n",
        "plt.plot(range(1, 21), accuracy_test, color= 'red', label = \"Test set accuracy\")\n",
        "plt.title('Accuracy Score vs. K Value')\n",
        "plt.legend()\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9_J8U6-UOXk",
        "outputId": "bb1f1297-8bb7-4b6c-8763-d767751bbb0b"
      },
      "source": [
        "# Train kNN classifier model for 'k = 15'\n",
        "knn15 = KNeighborsClassifier(n_neighbors = 15)\n",
        "knn15.fit(X_train, y_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train set and test set.\n",
        "print(\"Train set accuracy:\", knn15.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", knn15.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.6964675098124727\n",
            "Test set accuracy: 0.6510681586978637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwF3kG1-L12Y",
        "outputId": "c955359c-ee7d-41e1-cc0f-f9c6ba5c866a"
      },
      "source": [
        "# Display the precision, recall and f1-score values.\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, knn15.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.89      0.76       600\n",
            "           1       0.62      0.28      0.38       383\n",
            "\n",
            "    accuracy                           0.65       983\n",
            "   macro avg       0.64      0.58      0.57       983\n",
            "weighted avg       0.64      0.65      0.61       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WriY7XD6yjKY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buOXobLJykOv"
      },
      "source": [
        "#### Resampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUBYGAMY0ObI",
        "outputId": "99e25577-1dcd-494c-cbb0-8d4254a99c91"
      },
      "source": [
        "# Determine the percentage of samples belonging to class '0' and class '1' in 'y_train'.\n",
        "y_train.value_counts(normalize = True) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    60.968164\n",
              "1    39.031836\n",
              "Name: Potability, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFXT1dpR3B-f"
      },
      "source": [
        "\n",
        "**Resampling** is a common practice to address the imbalanced dataset issue. Although\n",
        "there are many techniques within resampling, here we’ll be learning the three most\n",
        "popular techniques:\n",
        "1. Random Undersampling\n",
        "2. Random Oversampling\n",
        "3. Synthetic Minority Oversampling Technique (SMOTE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9bOvx-WBjXL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP_kMcobBkar"
      },
      "source": [
        "#### Random Undersampling\n",
        "\n",
        "Random undersampling randomly selects and removes the samples from the majority class to match minority class count. Here, we will resample the target variable, `Potability`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pXwkGBHKEPC",
        "outputId": "f40f4d30-da63-4aa9-af9b-b08a5a5143a2"
      },
      "source": [
        "# Count the number of class 0 and 1 samples in train set before undersampling.\n",
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1398\n",
              "1     895\n",
              "Name: Potability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVu46_payVq_"
      },
      "source": [
        "# Perform random undersampling on train set\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state = 42)\n",
        "X_rus_train, y_rus_train = rus.fit_resample(X_train, y_train) # fit predictor and target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVC9d8q4Nquw",
        "outputId": "cd3b9c0b-b34b-4f03-e402-4e5c51d52a85"
      },
      "source": [
        "# Check the type and shapes of the 'X_rus_train' and 'y_rus_train' datasets.\n",
        "print(type(X_rus_train), X_rus_train.shape)\n",
        "print(type(y_rus_train), y_rus_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> (1790, 9)\n",
            "<class 'pandas.core.series.Series'> (1790,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "311b2OCQN3kw",
        "outputId": "34eba3a4-ca92-4401-9e7a-1e2655a13688"
      },
      "source": [
        "# Find the number of occurrences of class '0' and class '1' values in the 'y_rus_train' NumPy array.\n",
        "print(\"Number of class 0 samples:\", sum(y_rus_train == 0))\n",
        "print(\"Number of class 1 samples:\", sum(y_rus_train == 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of class 0 samples: 895\n",
            "Number of class 1 samples: 895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ4q9BnOyslu",
        "outputId": "278f0d54-4e10-4dc0-d0e4-23a9b46230cf"
      },
      "source": [
        "# Train kNN classifier model again for 'k = 15' with undersampled train set.\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_rus= KNeighborsClassifier(n_neighbors = 15)\n",
        "knn_rus.fit(X_rus_train, y_rus_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train and test set.\n",
        "print(\"Train set accuracy:\", knn_rus.score(X_rus_train, y_rus_train))\n",
        "print(\"Test set accuracy:\", knn_rus.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.6849162011173184\n",
            "Test set accuracy: 0.624618514750763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOBx-AFryy9G",
        "outputId": "630785c5-9124-4119-a47a-c3001079e1fb"
      },
      "source": [
        "# Display the precision, recall and f1-score values.\n",
        "print(classification_report(y_test, knn_rus.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.70      0.70       600\n",
            "           1       0.52      0.50      0.51       383\n",
            "\n",
            "    accuracy                           0.62       983\n",
            "   macro avg       0.60      0.60      0.60       983\n",
            "weighted avg       0.62      0.62      0.62       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUnYIXQxeJzc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mJQK-Bk15sm"
      },
      "source": [
        "#### Random Oversampling\n",
        "\n",
        "Random overrsampling randomly selects and added the samples from the minority class to match majority class count. Here, we will resample the target variable, `Potability`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WatVWlI82GWN"
      },
      "source": [
        "# Perform random undersampling on train set\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state = 42)\n",
        "X_ros_train, y_ros_train = ros.fit_resample(X_train, y_train) # fit predictor and target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffc9ZUwuaNLE",
        "outputId": "d4c1c1b0-8fe7-49a6-f068-5dd6d18e6151"
      },
      "source": [
        "# Check the type and shapes of the 'X_ros_train' and 'y_ros_train' datasets.\n",
        "print(type(X_ros_train), X_ros_train.shape)\n",
        "print(type(y_ros_train), y_ros_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> (2796, 9)\n",
            "<class 'pandas.core.series.Series'> (2796,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVUPbA0E2kT8",
        "outputId": "42be8e79-1b17-4431-eab4-837281d209b7"
      },
      "source": [
        "# Find the number of occurrences of class '0' and class '1' values in the 'y_ros_train' NumPy array.\n",
        "print(\"Number of class 0 samples:\", sum(y_ros_train == 0))\n",
        "print(\"Number of class 1 samples:\", sum(y_ros_train == 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of class 0 samples: 1398\n",
            "Number of class 1 samples: 1398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqcISgnY26hV",
        "outputId": "76dc6385-521e-4b80-8387-fc8565d3388e"
      },
      "source": [
        "# Train kNN classifier model for 'k = 15'\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_ros = KNeighborsClassifier(n_neighbors = 15)\n",
        "knn_ros.fit(X_ros_train, y_ros_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train and test set.\n",
        "print(\"Train set accuracy:\", knn_ros.score(X_ros_train, y_ros_train))\n",
        "print(\"Test set accuracy:\", knn_ros.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.7174535050071531\n",
            "Test set accuracy: 0.5839267548321465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5-Lq4nr3Tdc",
        "outputId": "ec3e42df-5ae5-4f3f-b706-4ca9d522c6ba"
      },
      "source": [
        "# Display the precision, recall and f1-score values.\n",
        "print(classification_report(y_test, knn_ros.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.66      0.66       600\n",
            "           1       0.47      0.47      0.47       383\n",
            "\n",
            "    accuracy                           0.58       983\n",
            "   macro avg       0.56      0.56      0.56       983\n",
            "weighted avg       0.58      0.58      0.58       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KQx5SowbFE2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaYINTUNa12u"
      },
      "source": [
        "#### Resampling using SMOTE\n",
        "\n",
        "SMOTE Resampling synthesizes the artificial data points for the minority class data to balance a highly imbalanced dataset. Here, we will resample the target variable, `Potability`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIGJCMmR3mE8"
      },
      "source": [
        "# Apply the 'SMOTE()' function to balance the training data.\n",
        "\n",
        "# Import the 'SMOTE' class from the 'imblearn.over_sampling' module.\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialise the 'SMOTE()' constructor.\n",
        "smote = SMOTE(random_state = 42)\n",
        "\n",
        "# Call the 'fit_sample()' function with 'X_train' and 'y_train' as inputs.\n",
        "X_sm_train, y_sm_train = smote.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj2A6kv33ue7",
        "outputId": "669752cc-f4fd-4b6a-fa0f-a6abc139f6a6"
      },
      "source": [
        "# Find the number of occurrences of class '0' and class '1' values in the 'y_sm_train' NumPy array.\n",
        "print(\"Number of class 0 samples:\", sum(y_sm_train == 0))\n",
        "print(\"Number of class 1 samples:\", sum(y_sm_train == 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of class 0 samples: 1398\n",
            "Number of class 1 samples: 1398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lme4gsp83y_9",
        "outputId": "1cabb650-39a3-4bec-c07b-fc3ca9e9480e"
      },
      "source": [
        "# Train kNN classifier model for 'k = 15'\n",
        "# Build the model.\n",
        "knn_sm = KNeighborsClassifier(n_neighbors = 15)\n",
        "\n",
        "# Call the 'fit()' function.\n",
        "knn_sm.fit(X_sm_train, y_sm_train)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the train and test set.\n",
        "print(\"Train set accuracy:\", knn_sm.score(X_ros_train, y_ros_train))\n",
        "print(\"Test set accuracy:\", knn_sm.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.6938483547925608\n",
            "Test set accuracy: 0.5859613428280773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz8atTQH4oBT",
        "outputId": "90750dd6-6dbb-45a2-edf3-dd5a8ec69648"
      },
      "source": [
        "# Display the precision, recall and f1-score values.\n",
        "print(classification_report(y_test, knn_sm.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.61      0.64       600\n",
            "           1       0.47      0.54      0.50       383\n",
            "\n",
            "    accuracy                           0.59       983\n",
            "   macro avg       0.57      0.58      0.57       983\n",
            "weighted avg       0.60      0.59      0.59       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmzH7puYh9RN"
      },
      "source": [
        "\n",
        "\n",
        "**Which resampling technique is the best❓**\n",
        "\n",
        "There is no one answer to this question! We can build classification models on the resampled datasets and compare the accuracy scores.\n",
        "\n",
        "By looking at various evaluation metrics obtained for each of the resampled datasets, we can say that **random undersampling** is performing better for both target labels for $k = 15$ nearest neighbour model.\n",
        "\n",
        "**Note:** You may obtain different accuracy scores for other $k$ values and thus, you can choose a resampling technique which provides the best result.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pkpb_D5RhQj"
      },
      "source": [
        "Let us now deploy Decision Tree classifier model and evaluate whether it can give better accuracy than kNN algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cue4gY3Wquiq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTGzOqrUJpRu"
      },
      "source": [
        "#### Activity 1: Building Decision Tree Classifier Model\n",
        "\n",
        "\n",
        "Let's proceed with **Decision Tree classifier** for the classifier design. We will  use `GridSearchCV` to obtain the optimal classifier hyperparameters.\n",
        "\n",
        "To tune the hyperparameters:\n",
        "\n",
        "1. Import the `DecisionTreeClassifier` class from the `sklearn.tree` module.\n",
        "\n",
        "2. Define dictionary, say `dtc_params` to select which parameters from `DecisionTreeClassifier` class you want to run the optimisation. Let us set:\n",
        "\n",
        "  - `criterion`: `['gini','entropy']` (function to measure the quality of a split).\n",
        "  \n",
        "  - `max_depth`: `2` to `10` (maximum depth of the tree).\n",
        "\n",
        "  - `min_samples_split`: `5` to `10` (minimum number of samples required to split an internal node).\n",
        "\n",
        "  - `min_samples_leaf` : `5` to `10` (minimum samples in leaf node).\n",
        "\n",
        "  \n",
        "3. Construct a decision tree grid `dtc_grid` using `GridSearchCV` function with following inputs:\n",
        "\n",
        " - `DecisionTreeClassifier (random_state = 42)`: The classifier model we want to deploy.\n",
        "\n",
        " - `dtc_params`: The set of parameters for which classifier performance would be evaluated.\n",
        "\n",
        " - `scoring`: Use `'accuracy'` as the scoring criteria.\n",
        "\n",
        "4. Call the `fit()` function on the `dtc_grid` to find the best fit and pass unbalanced train sets `X_train` and `y_train` as inputs.\n",
        "\n",
        "5. Print the hyperparameters which exhibit highest score using `dtc_grid.best_estimator_`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H1hhsXvLLb-",
        "outputId": "48a37a03-c0f3-4a75-cc85-36eea6201ac8"
      },
      "source": [
        "# S1.1: Obtain the optimal Decision Tree classifier hyperparameters using GridSearchCV\n",
        "\n",
        "# Import the required library\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameters grid for optimisation\n",
        "dtc_params = {'criterion':['gini','entropy'], 'max_depth': np.arange(2, 11),\n",
        "              'min_samples_split' : np.arange(5, 11),\n",
        "              'min_samples_leaf' : np.arange(5, 11),\n",
        "             }\n",
        "\n",
        "# Training\n",
        "dtc_grid = GridSearchCV(DecisionTreeClassifier(random_state = 42),\n",
        "                        dtc_params, scoring = 'accuracy' , n_jobs = -1)\n",
        "dtc_grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(dtc_grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=9,\n",
            "                       min_samples_split=5, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-FXSHKtNS6V"
      },
      "source": [
        "Here, we got the hyperparameters that gives the best estimator for Decision Tree Classifier on the training dataset.\n",
        "\n",
        "Next, let's model the problem using the best hyperparameters obtained from `GridSearchCV`. For this:\n",
        "\n",
        " 1. Create a `dtc_clf` object of `DecisionTreeClassifier` class and pass the hyperparameters obtained from `GridSearchCV`.\n",
        "\n",
        " 2. Call the `fit()` function on `dtc_clf` object with `X_train` and `y_train`.\n",
        "\n",
        " 3. Call the `predict()` function on the `dtc_clf` object with `X_test` as the input parameter.\n",
        "\n",
        " 4. Print the train and test set accuracy scores using `score()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK0hjkg9NgEr",
        "outputId": "21f9e856-16e9-4bcf-afc5-3efaec374ed3"
      },
      "source": [
        "# S1.2: Train a Decision tree model using the best hyperparameters.\n",
        "\n",
        "dtc_clf = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=9,\n",
        "                       min_samples_split=5, random_state=42)\n",
        "\n",
        "# Fit the DecisionTreeClassifier model and  perform prediction.\n",
        "dtc_clf.fit(X_train, y_train)\n",
        "dtc_y_pred = dtc_clf.predict(X_test)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the model.\n",
        "print(\"Train set accuracy:\", dtc_clf.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", dtc_clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.7117313563017881\n",
            "Test set accuracy: 0.6612410986775178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFL7UR9FNf40"
      },
      "source": [
        "The train set accuracy is around $72\\%$ and test set accuracy is around $66\\%$ which is less than that of SVC model. Let's print the classification report to get an in-depth overview of the classifier performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKDnnh6aOX5c",
        "outputId": "7edb101d-fecf-4e01-cb45-6ef2d13960dc"
      },
      "source": [
        "# S1.3: Print the classification report for DecisionTreeClassifier\n",
        "print(classification_report(y_test, dtc_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.92      0.77       600\n",
            "           1       0.66      0.26      0.38       383\n",
            "\n",
            "    accuracy                           0.66       983\n",
            "   macro avg       0.66      0.59      0.57       983\n",
            "weighted avg       0.66      0.66      0.62       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaTXEQlyJoPF"
      },
      "source": [
        "You may observe that the Decision Tree classifier is working well for target label `0`, but not for label `1`.  This may be due to unbalanced train set, hence you can use undersampled or oversampled train set and evaluate model's performance.\n",
        "\n",
        "Let us check how Random Forest classifier performs for unbalanced train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88KrEUN4m0NW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65tg2hlVlfD3"
      },
      "source": [
        "#### Activity 2: Building Random Forest Classifier Model\n",
        "\n",
        "Let us deploy Random Forest classifier model for the current problem statement. We will again use `GridSearchCV` to obtain the optimal classifier hyperparameters.\n",
        "\n",
        "Follow the steps given below to tune the hyperparameters needed for `RandomForestClassifier()` model:\n",
        "\n",
        "1. Import `GridSearchCV` class from the `sklearn.model_selection` module. Also, import the `RandomForestClassifier` class from `sklearn.ensemble` module.\n",
        "\n",
        "2. Define dictionary, say `rfc_params` to select which parameters from `RandomForestClassifier` class you want to run the optimisation. Let us set:\n",
        "\n",
        "  - `max_depth` (maximum depth of the tree): `[2, 5, 8, 10]`\n",
        "\n",
        "  - `n_estimators` (number of trees in the forest): `[10, 50, 100]`\n",
        "\n",
        "  \n",
        "\n",
        "3. Construct a Random forest grid `rfc_grid` using `GridSearchCV` function with following inputs:\n",
        "\n",
        " - `RandomForestClassifier(random_state = 42)`: The classifier model we want to deploy. Pass `random_state = 42` for getting consistent results.\n",
        "\n",
        " - `rfc_params`: The set of parameters for which classifier performance would be evaluated.\n",
        "\n",
        " - `scoring`: Use `'accuracy'` as the scoring criteria.\n",
        "\n",
        "4. Call the `fit()` function on the `rfc_grid` to find the best fit. Pass unbalanced train set `X_train` and `y_train` as inputs.\n",
        "\n",
        "  **Note:** As of now, we are  evaluating model's performance for only unbalanced train set. You can also test undersampled and oversampled train set's performance.\n",
        "\n",
        "5. Print the hyperparameters which exhibit highest score using `rfc_grid.best_estimator_`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRl9B7pQE0XO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34601010-1c1c-4647-8fd6-0cc9971e1545"
      },
      "source": [
        "# S2.1: Obtain the optimal Random forest classifier hyperparameters using GridSearchCV\n",
        "# Import the modules.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rfc_params = {\"max_depth\":[2, 5, 8, 10], \"n_estimators\":[10, 50, 100] }\n",
        "\n",
        "\n",
        "# Training.\n",
        "rfc_grid = GridSearchCV(RandomForestClassifier(random_state = 42), rfc_params,\n",
        "                        scoring = 'accuracy' , n_jobs = -1)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters.\n",
        "print(rfc_grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_depth=10, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhNUe1gqGzLE"
      },
      "source": [
        "Here, we got the hyperparameters that gives the best estimator for Random Forest Classifier on the training dataset.\n",
        "\n",
        "Next, let's build a Random Forest classifier model using the best hyperparameters obtained from `GridSearchCV`. For this:\n",
        "\n",
        " 1. Create a `rfc_clf` object of `RandomForestClassifier` class and pass the hyperparameters obtained from `GridSearchCV`.\n",
        "\n",
        " 2. Call the `fit()` function on `rfc_clf` object and pass unbalanced train set as inputs.\n",
        "\n",
        " 3. Call the `predict()` function on the `rfc_clf` object with `X_test` as the input parameter.\n",
        "\n",
        " 4. Print the train and test set accuracy scores using `score()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3bhyyGQEZWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d53f22-2c28-4cfb-ecdb-10a6ce49094f"
      },
      "source": [
        "# S2.2: Train an RandomForestClassifier model using the best hyperparameters.\n",
        "\n",
        "rfc_clf= RandomForestClassifier(max_depth=10, random_state=42)\n",
        "\n",
        "# Fit the model and perform prediction.\n",
        "rfc_clf.fit(X_train, y_train)\n",
        "rfc_y_pred = rfc_clf.predict(X_test)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the model.\n",
        "print(\"Train set accuracy:\", rfc_clf.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", rfc_clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.8477976450065416\n",
            "Test set accuracy: 0.6602238046795524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSplcNpHXQRn"
      },
      "source": [
        "The train set accuracy is around $85\\%$ and test set accuracy is around $66\\%$ which is good accuracy score. However let's print the classification report to get an in-depth overview of the classifier performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qN4o6vzXlWu",
        "outputId": "42563f81-f05c-48e8-becb-53820a4062a9"
      },
      "source": [
        "# S2.3: Print the classification report for Random forest classifier\n",
        "print(classification_report(y_test, rfc_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.94      0.77       600\n",
            "           1       0.70      0.22      0.34       383\n",
            "\n",
            "    accuracy                           0.66       983\n",
            "   macro avg       0.68      0.58      0.55       983\n",
            "weighted avg       0.67      0.66      0.60       983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvnPrj4DQaJx"
      },
      "source": [
        "You may observe that the similar to Decision Tree classifier, the Random Forest classifier is working well for target label `0`, but not for label `1`.  This may be due to unbalanced train set, hence you can use undersampled or oversampled train set and evaluate model's performance.\n",
        "\n",
        "Let us check how the Support Vector classifier performs for unbalanced train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoKJ8HkMJSJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw7KIJedYase"
      },
      "source": [
        "#### Activity 3: Building SVC Model\n",
        "\n",
        "Let's proceed with **Support Vector classifier** for the classifier design. We will again use `GridSearchCV` to obtain the optimal classifier hyperparameters.\n",
        "\n",
        "Follow the steps given below to tune the hyperparameters needed for `SVC()` model:\n",
        "\n",
        "\n",
        "1. Import the `SVC` class from the `sklearn.svm` module.\n",
        "\n",
        "\n",
        "2. Define dictionary, say `svc_params` to select which parameters from `SVC` class you want to run the optimisation. Let us set:\n",
        "\n",
        "  - `gamma`: `[1, 0.1]`\n",
        "\n",
        "  - `kernel`: `['rbf', 'linear']`\n",
        "\n",
        "3. Construct a SVC grid `svc_grid` using `GridSearchCV` function with following inputs:\n",
        "\n",
        " - `SVC (random_state = 42)`: The classifier model we want to deploy.\n",
        "\n",
        " - `svc_params`: The set of parameters for which classifier performance would be evaluated.\n",
        "\n",
        " - `scoring`: Use `'accuracy'` as the scoring criteria.\n",
        "\n",
        "4. Call the `fit()` function on the `svc_grid` to find the best fit. Pass the unbalanced train sets `X_train` and `y_train` as inputs.\n",
        "\n",
        "5. Print the hyperparameters which exhibit highest score using `svc_grid.best_params_`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwZbSvwbKSYJ",
        "outputId": "f99b563e-02d7-4acc-c724-037c482938b3"
      },
      "source": [
        "# S3.1: Obtain the optimal SVC classifier hyperparameters using GridSearchCV\n",
        "\n",
        "# Import the required library\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define the parameters grid for optimisation\n",
        "svc_params = {'gamma': [1, 0.1], 'kernel': ['rbf', 'linear']}\n",
        "\n",
        "# Training\n",
        "svc_grid = GridSearchCV(SVC(random_state = 42), svc_params, scoring = 'accuracy' , n_jobs = -1)\n",
        "svc_grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(svc_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gamma': 0.1, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkP0ZEFZ0xY"
      },
      "source": [
        "Here, we got the hyperparameters that gives the best estimator for Support Vector Classifier (SVC) on the training dataset.\n",
        "\n",
        "Next, let's model the problem using the best hyperparameters obtained from `GridSearchCV`. For this:\n",
        "\n",
        " 1. Create a `svc_clf` object of `SVC` class and pass the hyperparameters obtained from `GridSearchCV`.\n",
        "\n",
        " 2. Call the `fit()` function using the `svc_clf` object with `X_train` and `y_train`.\n",
        "\n",
        " 3. Call the `predict()` function using the `svc_clf` object with `X_test` as the input parameter.\n",
        "\n",
        " 4. Print the train and test set accuracy scores using `score()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwcHJNbxBWQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e230a688-5bf3-4f2e-c6dd-e6865d148458"
      },
      "source": [
        "# S3.2: Train an SVC model using the best hyperparameters.\n",
        "\n",
        "svc_clf = SVC(gamma = 0.1,  kernel = 'rbf', random_state = 42)\n",
        "\n",
        "# Fit the SVC model and  perform prediction.\n",
        "svc_clf.fit(X_train, y_train)\n",
        "svc_y_pred = svc_clf.predict(X_test)\n",
        "\n",
        "# Call the 'score()' function to check the accuracy score of the model.\n",
        "print(\"Train set accuracy:\", svc_clf.score(X_train, y_train))\n",
        "print(\"Test set accuracy:\", svc_clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 0.7287396423898822\n",
            "Test set accuracy: 0.6826042726347915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ivw4WlkbQa4"
      },
      "source": [
        "The train set accuracy is around $73\\%$ and test set accuracy is around $68\\%$. Let's print the classification report to get an in-depth overview of the classifier performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7afzrlvbjZI"
      },
      "source": [
        "# S3.3: Print the classification report for SVC classifier\n",
        "print(classification_report(y_test, svc_y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_MuJf3zbyQX"
      },
      "source": [
        "You may observe that the SVC classifier is working well for both the target labels when unbalanced train set is used. However, its overall accuracy is less than Random Forest classifier but more than Decision Tree classifier.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Hence, SVC model performs better than kNN and Random forest models in predicting both the target labels when the train set is unbalanced. So what conclusions can be drawn after evaluating the four classifier models?\n",
        "\n",
        "**Conclusions:**\n",
        "1. Try a bunch of algorithms and compare their performances to choose the best one for your specific task.\n",
        "\n",
        "2. Always start with simpler models like kNN and Logistic Regression. Complex models like Random Forest classifier and SVC involves many hyperparameters. Tuning these hyperparameters to improve accuracy may result in overfitting as the model would try to learn too much from the training data.\n",
        "\n",
        "  Hence, use these complex models only when the less complex models like  kNN and Logistic Regression which involves less hyperparameters are not giving satisfactory accuracy scores for all the target labels.\n",
        "\n",
        "3. Perform undersampling and oversampling only when the dataset is highly imbalanced and the f1 scores for all the target labels are not satisfactory.\n",
        "\n",
        "\n",
        "Congratulations! You have successfully implemented kNN algorithm to solve a classification problem where the algorithm predicts discrete values such as `0` and `1` or `Yes` and `No`. Let us now learn how to use kNN algorithm to predict continuous values such as price, salary, age etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGcgN4vehubY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6ddMxCoh69o"
      },
      "source": [
        "#### Activity 4: Applying kNN for Regression\n",
        "\n",
        "\n",
        "Suppose we have age, height, and weight for 10 people and we need to predict the weight of a new person using the age and height information that we have.\n",
        "\n",
        "The data including age, height, and weight information is shown below:\n",
        "\n",
        "<center><img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/86c216dc-5981-4381-9c59-40c2cd70fa53.PNG\"/></center>\n",
        "\n",
        "Let us create a pandas DataFrame containing the above columns by using the following dictionary:\n",
        "\n",
        "```python\n",
        "data_dict = {'ID':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "\t\t'age': [45, 32, 26, 23, 28, 30, 34, 19, 36, 40],\n",
        "\t\t'height':[5, 5.6, 5.11, 5.5, 5.8, 5.6, 5.9, 5.3, 5.8, 4.8],\n",
        "\t  'weight' : [77, 58, 47, 45, 60, 55, 59, 40, 60, 72]}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMz4eo4RpPKd"
      },
      "source": [
        "# S4.1: Create a dataset for age, height and weight of people\n",
        "data_dict = {'ID':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "\t\t'age': [45, 32, 26, 23, 28, 30, 34, 19, 36, 40],\n",
        "\t\t'height':[5, 5.6, 5.11, 5.5, 5.8, 5.6, 5.9, 5.3, 5.8, 4.8],\n",
        "\t  'weight' : [77, 58, 47, 45, 60, 55, 59, 40, 60, 72]}\n",
        "\n",
        "# Create a DataFrame from the dictionary\n",
        "data_df = pd.DataFrame(data_dict)\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsuBVeW-rnEN"
      },
      "source": [
        "Let's plot the `age` and `height` of persons on a  scatter plot. Also annotate each data point with their ID number. For example, first data point must be labelled as `1`, second data point must be labelled as `2` and so on. For this purpose, use `annotate()` function of `matplotlib.pyplot` module.\n",
        "\n",
        "You can use `help()` function to understand the syntax of `annotate()` function in detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIhqaxMfr_yP"
      },
      "source": [
        "# S4.2: Create a scatter plot showing person's age and height with each data point numbered using their ID.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.title('age vs height')\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('height')\n",
        "\n",
        "# Plot a scatter plot and using a loop annotate the points\n",
        "plt.scatter(data_df['age'], data_df['height'])\n",
        "for label, x, y in zip(data_df['ID'], data_df['age'], data_df['height']):\n",
        "    plt.annotate(label, xy=(x, y), xytext=(1, 4), textcoords='offset points')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0eQraAStuSN"
      },
      "source": [
        "In the above graph, the $x$-axis represents the age of a person (in years) and the $y$-axis represents the height (in feet). The points are numbered according to the ID values.\n",
        "\n",
        "Suppose there is a new person having ID as `11` whose age is `38` and height is `5.5`. We need to predict the weight of this person based on his age and height.\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/5c2d5530-37a0-4533-9490-d5eebcb141f9.png\"/>\n",
        "\n",
        "In the above graph, the person with ID11 is our test point. If we try to identify the weight of ID11 based on the plot, we would say that since ID11 is closer to points `2` and `9`, so it must have a weight similar to these IDs. Let us find out how kNN algorithm  predicts the weight of ID11.\n",
        "\n",
        "**How kNN regression work?**\n",
        "\n",
        "In kNN, a new data point is assigned a value based on how closely it resembles the points in the training set. From our example, we know that ID11 has height and age similar to ID2 and ID9, so the weight would also approximately be the same.\n",
        "\n",
        "If we use kNN classifier in this case, it would assign the new data point ID11 to the class to which the majority of its nearest points belong. So the weight of ID11 would be equal to weight of either ID2 or ID9 (if $k = 2$).\n",
        "\n",
        "However, in kNN regression, the average of the values is taken to be the final prediction. Thus, the weight of ID11 would be the mean of weights of ID2 and ID9 (if $k = 2$) for kNN regression.\n",
        "\n",
        "Thus, kNN regression has the following basic steps:\n",
        "\n",
        "<center><img src= \"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/11ad6a31-50bd-4ec4-aea0-e947a832e296.png\"/></center>\n",
        "\n",
        "Let us first calculate the distance between the new data point and each training point. The most commonly used distance metric is Euclidean distance.\n",
        "\n",
        "First, create a separate DataFrame containing only the feature variables i.e. `age` and `height`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbi5CA1j2T-R"
      },
      "source": [
        "# S4.3: Create a separate DataFrame containing the feature variables.\n",
        "feature_df = data_df[['age', 'height']]\n",
        "feature_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WijqLAC2p4"
      },
      "source": [
        "We can calculate the Euclidean distance between each data point of `feature_df` and the new data point ID11(`38`, `5.5`) using `linalg.norm()` function of `numpy` module.\n",
        "\n",
        "**Syntax of `linalg.norm()` function:** `np.linalg.norm(data_1 - data_2, axis = 1)`\n",
        "\n",
        "Where,\n",
        "- `data_1` and `data_2` are the two data points whose euclidean distance is to be calculated.\n",
        "- `axis = 1` indicates that each row of DataFrame has to be normalised separately.\n",
        "\n",
        "**Note:** Use `to_numpy()` function to convert each row of DataFrame to a NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFap09y2tTS"
      },
      "source": [
        "# S4.4: Compute Euclidean distance between training data and ID11\n",
        "id11 = [38, 5.5]\n",
        "dist_from_id11 = np.linalg.norm(feature_df.to_numpy() - id11, axis = 1)\n",
        "dist_from_id11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXaWz95CGgVg"
      },
      "source": [
        "Hence, we have obtained a NumPy array containing the  distances of all the 10 training points from the new data point ID11. Let us add this array as a new column to the original DataFrame `data_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBmjvmc14aVZ"
      },
      "source": [
        "# S4.5: Add the distance array as a new column to the original dataset.\n",
        "data_df['Distance from ID11 (38, 5.5)'] = dist_from_id11\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkhO2-DE4Zq4"
      },
      "source": [
        "Hence, we have obtained the Euclidean distance between each training point and the new data point ID11(age = 38, height = 5.5).\n",
        "\n",
        "- If $k = 1$, then the nearest neighbour would be **ID9** as the distance between ID9 and ID11 is the least as seen in the image below:\n",
        "\n",
        "  <center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/f02c09a7-7575-4762-bdbc-aeba744fff5c.PNG\"/>\n",
        "\n",
        "  `Fig 4.1: When k = 1`\n",
        "  </center>\n",
        "\n",
        "  In this case, the predicted weight of ID11 would be `60`, which is same as the weight of ID9.\n",
        "\n",
        "\n",
        "- If $k = 3$, then prediction of ID11 will be the average of weights of top 3 closest neighbours.\n",
        "\n",
        "  <center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/568bf765-09aa-440e-84ce-2713e64876d4.png\"/>\n",
        "\n",
        "  `Fig 4.2: When k = 3`\n",
        "  </center>\n",
        "\n",
        "  In this case, the predicted weight of ID11 would be:\n",
        "  \n",
        "  $$\\text{Weight of ID11} = \\frac{(60 + 72 + 59)}{3} = 63.67 kg$$\n",
        "\n",
        "\n",
        "\n",
        "Thus, in kNN regression, the predicted value is the average of the values of $k$ nearest neighbours.\n",
        "\n",
        "We will stop here. In the next class, we will implement kNN regression on a real world dataset using `sklearn` module.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KYruXRXn4a"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ_O0tC5AFVs"
      },
      "source": [
        "#### Activities\n",
        "\n",
        "\n",
        "**Teacher Activities:**\n",
        "\n",
        "1. kNN Regression I (Class Copy)\n",
        "\n",
        "   Link on Panel\n",
        "   \n",
        "2. kNN Regression I (Reference)\n",
        "\n",
        "    Link on Panel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWSZZyk8AGRb"
      },
      "source": [
        "---"
      ]
    }
  ]
}